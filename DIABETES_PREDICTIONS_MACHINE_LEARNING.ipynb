{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **DIABETES PREDICTION PROJECT**"
      ],
      "metadata": {
        "id": "60miVjiNU9Hv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IMPORT LIBRARIES"
      ],
      "metadata": {
        "id": "9ZHyaA1DVKRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, precision_recall_curve\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.inspection import permutation_importance\n",
        "import shap\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "bXhA9PLfVJSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced styling options\n",
        "plt.rcParams['figure.figsize'] = (12, 8)  # Set default figure size for better detail\n",
        "plt.rcParams['font.size'] = 12  # Increase base font size for better readability\n",
        "plt.rcParams['axes.titlesize'] = 16  # Make titles more prominent\n",
        "plt.rcParams['axes.labelsize'] = 14  # Make axis labels stand out\n",
        "\n",
        "# For medical-specific visualizations\n",
        "sns.set_context(\"talk\")  # Larger elements, suited for presentations\n",
        "plt.rcParams['axes.titleweight'] = 'bold'  # Bold titles for emphasis"
      ],
      "metadata": {
        "id": "92d6g3ZhWCgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. DATA ACQUISITION\n",
        "print(\"Phase 1: Data Acquisition and Initial Exploration\")\n",
        "print(\"-------------------------------------------------\")"
      ],
      "metadata": {
        "id": "FawRjzk-WOM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load the datasets\n"
      ],
      "metadata": {
        "id": "fjgEPXtxW12M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv')"
      ],
      "metadata": {
        "id": "yf82e5uyW7Hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',\n",
        "                'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
        "df.columns = column_names"
      ],
      "metadata": {
        "id": "YBq_sA6zB5OF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(\"\\nFirst few records:\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "Oo3QMm6EXUJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploratory Data Analysis (EDA)**"
      ],
      "metadata": {
        "id": "CKQaYNecjdGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "feneQfMEXw9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = df.describe()\n",
        "print(\"Summary Statistics:\")"
      ],
      "metadata": {
        "id": "Yfbn926nZCnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zero_counts = (df == 0).sum()  # Count zeros in each column\n",
        "print(zero_counts)"
      ],
      "metadata": {
        "id": "215gwdRacXaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Converting impossible zero values to missing values (NaN):\")"
      ],
      "metadata": {
        "id": "JBW11qwTcgTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zero_columns = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']"
      ],
      "metadata": {
        "id": "eD_EqJjpcgMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "medical_reasons = {\n",
        "    'Glucose': 'Blood glucose cannot be zero in living patients',\n",
        "    'BloodPressure': 'Blood pressure of zero would indicate death',\n",
        "    'SkinThickness': 'Skin fold thickness cannot be zero',\n",
        "    'Insulin': 'Missing insulin test rather than actual zero',\n",
        "    'BMI': 'BMI cannot be zero for a person with physical mass'\n",
        "}\n",
        "for col in zero_columns:\n",
        "    df[col] = df[col].replace(0, np.nan)"
      ],
      "metadata": {
        "id": "EsmcqWw7cgHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isna().sum())"
      ],
      "metadata": {
        "id": "pJJ63S7bcgEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTarget Distribution:\")\n",
        "outcome_counts = df['Outcome'].value_counts()\n",
        "print(outcome_counts)\n",
        "print(f\"Percentage of diabetic patients: {outcome_counts[1] / len(df) * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "LptoVG03cf_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualization by the outcome\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, col in enumerate(df.columns[:-1]):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    sns.histplot(data=df, x=col, hue='Outcome', element='step', kde=True, bins=20)\n",
        "    plt.title(f'Distribution of {col} by Outcome', fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.savefig('feature_distributions.png')"
      ],
      "metadata": {
        "id": "GqUukzvVdtYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation analysis\n",
        "plt.figure(figsize=(10,8))\n",
        "correlation_matrix = df.corr().round(2)\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
        "plt.title('Feature Correlation Matrix')\n",
        "plt.savefig('correlation_matrix.png')\n"
      ],
      "metadata": {
        "id": "A2G61TPXe01O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**"
      ],
      "metadata": {
        "id": "VDw0OLSafDfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('Outcome', axis=1)\n",
        "y = df['Outcome']"
      ],
      "metadata": {
        "id": "3elTh2pDe5sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "uJqkFyRJfnMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessing_pipeline = Pipeline([\n",
        "    ('imputer', KNNImputer(n_neighbors=5)),  # Advanced imputation\n",
        "    ('scaler', RobustScaler())  # Robust to outliers\n",
        "])"
      ],
      "metadata": {
        "id": "Ut-mAfXFfzv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_processed = preprocessing_pipeline.fit_transform(X_train)\n",
        "X_test_processed = preprocessing_pipeline.transform(X_test)"
      ],
      "metadata": {
        "id": "r6X4y4HffztU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_processed_df = pd.DataFrame(\n",
        "    X_train_processed,\n",
        "    columns=X_train.columns\n",
        ")\n",
        "print(X_train_processed_df.describe().round(2))"
      ],
      "metadata": {
        "id": "KqWtZywLfzjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "PYKZWpOdf_Ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Engineering**"
      ],
      "metadata": {
        "id": "4ChgF3WZgWY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_processed_df['Glucose_BMI'] = X_train_processed_df['Glucose'] * X_train_processed_df['BMI']\n",
        "X_train_processed_df['Age_BMI'] = X_train_processed_df['Age'] * X_train_processed_df['BMI']\n",
        "X_train_processed_df['Glucose_Age'] = X_train_processed_df['Glucose'] * X_train_processed_df['Age']\n"
      ],
      "metadata": {
        "id": "RAKJhwEygNAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_processed_df = pd.DataFrame(\n",
        "    X_test_processed,\n",
        "    columns=X_train.columns\n",
        ")\n",
        "X_test_processed_df['Glucose_BMI'] = X_test_processed_df['Glucose'] * X_test_processed_df['BMI']\n",
        "X_test_processed_df['Age_BMI'] = X_test_processed_df['Age'] * X_test_processed_df['BMI']\n",
        "X_test_processed_df['Glucose_Age'] = X_test_processed_df['Glucose'] * X_test_processed_df['Age']\n",
        "\n",
        "print(f\"Features after engineering: {X_train_processed_df.columns.tolist()}\")\n",
        "print(f\"New feature set shape: {X_train_processed_df.shape}\")\n",
        "\n",
        "# Convert back to numpy arrays for model training\n",
        "X_train_final = X_train_processed_df.values\n",
        "X_test_final = X_test_processed_df.values\n"
      ],
      "metadata": {
        "id": "rij6MhLdg3tK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Selection and Training**\n"
      ],
      "metadata": {
        "id": "Hhbc7v-2hnKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_model = RandomForestClassifier(random_state=42)"
      ],
      "metadata": {
        "id": "Ed_wxlsYhhHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of data preprocessing steps before Model Selection and Training\n",
        "\n",
        "# Assuming you have already completed data preprocessing steps like handling missing values,\n",
        "# feature engineering, scaling, etc.\n",
        "\n",
        "# Let's assume we have the processed data as `X_train_processed_df` and `y_train`\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Example of splitting the data (use your processed data here)\n",
        "X = X_train_processed_df  # Features after preprocessing and engineering\n",
        "y = y_train  # Target variable (diabetes diagnosis)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train_final, X_test_final, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Now, you can proceed with the model selection and training phase\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "print(\"\\nPhase 5: Model Selection and Training\")\n",
        "print(\"----------------------------------\")\n",
        "\n",
        "# 1. Initial Random Forest Model\n",
        "initial_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# 2. Cross-validation strategy using StratifiedKFold to ensure class distribution is maintained\n",
        "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Cross-validation evaluation: ROC-AUC is used as it is a suitable metric for medical classification problems\n",
        "cv_scores = cross_val_score(initial_model, X_train_final, y_train, cv=cv_strategy, scoring='roc_auc')\n",
        "\n",
        "# Display cross-validation results\n",
        "print(f\"Initial model cross-validation ROC-AUC: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}\")\n",
        "\n",
        "# 3. Hyperparameter tuning using GridSearchCV\n",
        "# This will search over a grid of hyperparameters and evaluate using ROC-AUC\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],            # Number of trees in the forest\n",
        "    'max_depth': [None, 10, 20, 30],             # Depth of trees\n",
        "    'min_samples_split': [2, 5, 10],             # Minimum samples required to split an internal node\n",
        "    'min_samples_leaf': [1, 2, 4],               # Minimum samples required to be at a leaf node\n",
        "    'max_features': ['sqrt', 'log2', None]      # Number of features to consider at each split\n",
        "}\n",
        "\n",
        "# GridSearchCV for hyperparameter optimization with ROC-AUC as the scoring metric\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=RandomForestClassifier(random_state=42),\n",
        "    param_grid=param_grid,\n",
        "    cv=cv_strategy,                             # Cross-validation strategy\n",
        "    scoring='roc_auc',                          # Scoring based on ROC-AUC\n",
        "    n_jobs=-1,                                  # Use all CPU cores to speed up the search\n",
        "    verbose=1                                   # Display progress while searching\n",
        ")\n",
        "\n",
        "# 4. Fit the grid search to the data to find the best hyperparameters\n",
        "grid_search.fit(X_train_final, y_train)\n",
        "\n",
        "# 5. Display the best hyperparameters and the best score from cross-validation\n",
        "print(f\"\\nBest hyperparameters: {grid_search.best_params_}\")\n",
        "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# 6. Train the final model with the best hyperparameters\n",
        "best_model = grid_search.best_estimator_\n",
        "best_model.fit(X_train_final, y_train)\n",
        "\n",
        "# 7. Predict on the test data and evaluate the model\n",
        "y_pred = best_model.predict(X_test_final)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nTest ROC-AUC: {roc_auc:.4f}\")\n"
      ],
      "metadata": {
        "id": "H2uAOoRNiIUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Evaluation**"
      ],
      "metadata": {
        "id": "zq3aQn3knSCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "y_pred = best_model.predict(X_test_final)\n",
        "y_pred_proba = best_model.predict_proba(X_test_final)[:, 1]"
      ],
      "metadata": {
        "id": "pRfkY3LqnXaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)"
      ],
      "metadata": {
        "id": "MoEIxYSvnjBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall (Sensitivity): {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n"
      ],
      "metadata": {
        "id": "0eg8uKKinlKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.savefig('confusion_matrix.png')"
      ],
      "metadata": {
        "id": "YIEA_6caoHfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "xgzb1CvEoSZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC Curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "plt.plot(fpr, tpr, label=f'RandomForest (AUC = {roc_auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.savefig('roc_curve.png')"
      ],
      "metadata": {
        "id": "8rCfeKnXonkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision-Recall Curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_proba)\n",
        "plt.plot(recall_curve, precision_curve)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.savefig('precision_recall_curve.png')"
      ],
      "metadata": {
        "id": "8LZ8TjWooq_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Interpretation**"
      ],
      "metadata": {
        "id": "iFvdGF0qppng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Understanding the model's decision-making is crucial for clinical applications\n",
        "feature_names = list(X_train_processed_df.columns)\n",
        "importances = best_model.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]"
      ],
      "metadata": {
        "id": "ElAvlw5Np5rB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.title('Feature Importance')\n",
        "plt.bar(range(len(importances)), importances[indices], align='center')\n",
        "plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.savefig('feature_importance.png')"
      ],
      "metadata": {
        "id": "Av7kM-_hqKOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(importances)):\n",
        "    print(f\"{i+1}. {feature_names[indices[i]]}: {importances[indices[i]]:.4f}\")"
      ],
      "metadata": {
        "id": "2oMr6M-SqKLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Permutation Importance - more reliable for correlated features\n",
        "perm_importance = permutation_importance(\n",
        "    best_model, X_test_final, y_test, n_repeats=10, random_state=42\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sorted_idx = perm_importance.importances_mean.argsort()\n",
        "plt.boxplot(perm_importance.importances[sorted_idx].T,\n",
        "            vert=False, labels=[feature_names[i] for i in sorted_idx])\n",
        "plt.title(\"Permutation Importances\")\n",
        "plt.tight_layout()\n",
        "plt.savefig('permutation_importance.png')\n"
      ],
      "metadata": {
        "id": "c6tOFhDjqNw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Ensure feature names are available, usually you can take it from the dataframe columns\n",
        "feature_names = X_test_final.columns\n",
        "\n",
        "# SHAP Explainer for Random Forest\n",
        "explainer = shap.TreeExplainer(best_model)\n",
        "shap_values = explainer.shap_values(X_test_final)\n",
        "\n",
        "# If it's a binary classification, shap_values will have two sets, one for each class.\n",
        "# For binary classification, use shap_values[1] for the positive class.\n",
        "# For multi-class classification, loop through all classes, or use shap_values[0] for the first class.\n",
        "\n",
        "# Check if it's binary or multi-class and adjust accordingly\n",
        "if isinstance(shap_values, list):\n",
        "    shap_values_class = shap_values[1]  # For the positive class in binary classification\n",
        "else:\n",
        "    shap_values_class = shap_values\n",
        "\n",
        "# Plotting SHAP summary plot\n",
        "plt.figure(figsize=(10, 8))\n",
        "shap.summary_plot(shap_values_class, X_test_final, feature_names=feature_names, show=False)\n",
        "plt.title(\"SHAP Feature Impact Summary\")\n",
        "plt.tight_layout()\n",
        "plt.savefig('shap_summary.png')\n"
      ],
      "metadata": {
        "id": "gJlwzvMSqYje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL DEPLOYMENT PREPARATION**"
      ],
      "metadata": {
        "id": "chS9D3hasM4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the preprocessing pipeline and model for deployment\n",
        "import joblib\n",
        "\n",
        "# Save the preprocessing pipeline\n",
        "joblib.dump(preprocessing_pipeline, 'diabetes_preprocessing_pipeline.pkl')\n",
        "\n",
        "# Save the feature engineering function\n",
        "def engineer_features(df):\n",
        "    \"\"\"\n",
        "    Add engineered features to the input dataframe\n",
        "    \"\"\"\n",
        "    df_copy = df.copy()\n",
        "    df_copy['Glucose_BMI'] = df_copy['Glucose'] * df_copy['BMI']\n",
        "    df_copy['Age_BMI'] = df_copy['Age'] * df_copy['BMI']\n",
        "    df_copy['Glucose_Age'] = df_copy['Glucose'] * df_copy['Age']\n",
        "    return df_copy\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(best_model, 'diabetes_prediction_model.pkl')\n"
      ],
      "metadata": {
        "id": "sWKpwXQ8qnS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "wyiw9Pg_DUtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample prediction function\n",
        "def predict_diabetes_risk(patient_data):\n",
        "    \"\"\"\n",
        "    Make diabetes risk prediction for new patient data\n",
        "\n",
        "    Parameters:\n",
        "    patient_data (dict): Dictionary with patient features\n",
        "\n",
        "    Returns:\n",
        "    dict: Prediction results including probability and risk category\n",
        "    \"\"\"\n",
        "    # Convert input to DataFrame\n",
        "    patient_df = pd.DataFrame([patient_data])\n",
        "\n",
        "    # Preprocess the data\n",
        "    patient_processed = preprocessing_pipeline.transform(patient_df)\n",
        "    patient_processed_df = pd.DataFrame(\n",
        "        patient_processed,\n",
        "        columns=patient_df.columns\n",
        "    )\n",
        "\n",
        "    # Apply feature engineering\n",
        "    patient_final = engineer_features(patient_processed_df)\n",
        "\n",
        "    # Make prediction\n",
        "    risk_prob = best_model.predict_proba(patient_final.values)[0, 1]\n",
        "    risk_prediction = 1 if risk_prob >= 0.5 else 0\n",
        "\n",
        "    # Risk category\n",
        "    if risk_prob < 0.2:\n",
        "        risk_category = \"Low Risk\"\n",
        "    elif risk_prob < 0.5:\n",
        "        risk_category = \"Moderate Risk\"\n",
        "    elif risk_prob < 0.7:\n",
        "        risk_category = \"High Risk\"\n",
        "    else:\n",
        "        risk_category = \"Very High Risk\"\n",
        "\n",
        "    return {\n",
        "        \"prediction\": risk_prediction,\n",
        "        \"probability\": risk_prob,\n",
        "        \"risk_category\": risk_category\n",
        "    }\n"
      ],
      "metadata": {
        "id": "0scqdh6ZKsl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "sample_patient = pd.DataFrame({\n",
        "    'Pregnancies': [2],\n",
        "    'Glucose': [120],\n",
        "    'BloodPressure': [70],\n",
        "    'SkinThickness': [20],\n",
        "    'Insulin': [79],\n",
        "    'BMI': [25.5],\n",
        "    'DiabetesPedigreeFunction': [0.5],\n",
        "    'Age': [32]\n",
        "})\n",
        "\n",
        "# Get training data columns and their order\n",
        "training_columns = X_train_processed_df.columns\n",
        "\n",
        "# Ensure all features exist in the sample patient data, and in the correct order\n",
        "for col in training_columns:\n",
        "    if col not in sample_patient.columns:\n",
        "        sample_patient[col] = 0  # or suitable default\n",
        "\n",
        "# Reorder columns to match training data\n",
        "sample_patient = sample_patient[training_columns]\n",
        "\n",
        "# Now predict\n",
        "risk_prob = best_model.predict_proba(sample_patient)[0, 1]\n",
        "risk_prediction = 1 if risk_prob >= 0.5 else 0\n",
        "\n",
        "print(f\" Predicted Diabetes Risk Probability: {risk_prob:.2f}\")\n",
        "print(f\" Predicted Diabetes Risk Class (0=No, 1=Yes): {risk_prediction}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "9YGMuRMnO0oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KRZaEcpOPcYC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}